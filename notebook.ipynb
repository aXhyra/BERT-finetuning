{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Fine_Tuning.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Finetuning DistilBERT on tweet-eval dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/aXhyra/BERT-finetuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -r requirements.txt\n",
    "!git lfs install"
   ],
   "metadata": {
    "id": "1SaYsilNuF-g"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from helper import LoginHelper, Engine, Dataset\n",
    "from helper.engine import retrieve_hyperparameter_config\n",
    "from helper.dataset import compute_metrics"
   ],
   "metadata": {
    "id": "5WWBp9BD-CM0"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HuggingFace and wandb login"
   ],
   "metadata": {
    "id": "F2VXAimBHHGJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"hf_token\"] = \"YOUR_HUGGINGFACE_TOKEN\"\n",
    "os.environ[\"wandb_token\"] = \"YOUR_WANDB_TOKEN\"\n",
    "LoginHelper(wandb_project_name=\"BERT-finetuning\", wandb_save_models=True, tokenizer_parallelism=False)"
   ],
   "metadata": {
    "id": "mTBAbqanGQGb",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run hyperparameter search and train a model per seed on the best parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tasks = [\"irony\", \"emotion\", \"hate\", \"sentiment\"]\n",
    "seeds = [42, 31415, 1234567]\n",
    "\n",
    "batch_size = 16\n",
    "metric_name = \"f1\"\n",
    "\n",
    "for task in tasks:\n",
    "    name = f\"{task}_hyperparameter_search\"\n",
    "    args = TrainingArguments(\n",
    "        name,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=False,\n",
    "        push_to_hub = False,\n",
    "        metric_for_best_model=metric_name,\n",
    "        report_to=\"wandb\",\n",
    "        save_total_limit=1,\n",
    "        run_name=name\n",
    "    )\n",
    "\n",
    "    dataset = Dataset(task, \"distilbert-base-uncased\")\n",
    "    engine = Engine(dataset, args)\n",
    "\n",
    "    engine.hyperparameter_search(10)\n",
    "    for seed in seeds:\n",
    "        name = f\"{task}_trained\"\n",
    "        print(f\"\\n\\n [+] Training model: {name}\")\n",
    "        engine.train(4, seed=0, opt_name=name)\n",
    "        os.system(f\"rm -rf {name}\")\n"
   ],
   "metadata": {
    "id": "DG4n55tlhiXc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve configurations from best trained models and train them on three seeds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seeds = [42, 31415, 1234567]\n",
    "model_repo = {\"irony\": \"aXhyra\", \"emotion\": \"aXhyra\", \"hate\": \"aXhyra\", \"sentiment\": \"aXhyra\"}\n",
    "\n",
    "for model_name, author in model_repo.items():\n",
    "    dataset = Dataset(\"model_name\", \"distilbert-base-uncased\")\n",
    "    model = f\"{author}/{model_name}_trained\"\n",
    "    lr, batch_size, metric_name = retrieve_hyperparameter_config(model)\n",
    "    for seed in seeds:\n",
    "        name = f\"{model_name}_trained_{seed}\"\n",
    "        args = TrainingArguments(\n",
    "            name,\n",
    "            seed=seed,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=4,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            push_to_hub=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            report_to=\"wandb\",\n",
    "            save_total_limit=1,\n",
    "            run_name=name,\n",
    "        )\n",
    "    engine = Engine(dataset, args)\n",
    "    engine.train(4, seed=seed, opt_name=model, use_given_args=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate trained models on test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tasks = ['irony', 'emotion', 'hate', 'sentiment']\n",
    "seeds = [42, 31415, 1234567]\n",
    "\n",
    "mean_test_eval = {}\n",
    "std_test_eval = {}\n",
    "best_test_eval = {}\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    tmp_res = []\n",
    "    for s in seeds:\n",
    "        metric = 'f1' if task == 'irony' else 'recall'\n",
    "        model_path = f\"aXhyra/{task}_trained_{s}\"\n",
    "        res = Engine.test_eval(model_path, task, compute_metrics(metric))\n",
    "        tmp_res.append(res[f'eval_{metric}'])\n",
    "    mean_test_eval[task] = np.mean(tmp_res)\n",
    "    std_test_eval[task] = np.std(tmp_res)\n",
    "    best_test_eval[task] = max(tmp_res)\n",
    "\n",
    "print(mean_test_eval)\n",
    "print(std_test_eval)\n",
    "print(best_test_eval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "engine.predict(\"I love this movie\")"
   ],
   "metadata": {
    "id": "eDj-lf7PdzqX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "outputId": "5993d161-87be-4691-bc8c-00f4b44c5630"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'positive'"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ]
  }
 ]
}